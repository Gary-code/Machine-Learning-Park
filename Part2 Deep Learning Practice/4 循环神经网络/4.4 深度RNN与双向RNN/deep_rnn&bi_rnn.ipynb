{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.4 深度循环神经网络与双向循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "# 加载数据集，祖传时间机器数据集\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.1 深度RNN\n",
    "\n",
    "我们可以将多层循环神经网络堆叠在一起， 通过对几个简单层的组合来新成深度循环神经网络。其模型架构图如下所示:\n",
    "\n",
    "![image-20220209101701578](https://s2.loli.net/2022/02/09/N87FWXUhrwPRbBk.png)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathbf{H}_{t}^{1}=f_{1}\\left(\\mathbf{H}_{t-1}^{1}, \\mathbf{X}_{t}\\right) \\\\\n",
    "&\\quad \\ldots \\\\\n",
    "&\\mathbf{H}_{t}^{j}=f_{j}\\left(\\mathbf{H}_{t-1}^{j}, \\mathbf{H}_{t}^{j-1}\\right) \\\\\n",
    "&\\quad \\cdots \\\\\n",
    "&\\quad \\mathbf{O}_{t}=g\\left(\\mathbf{H}_{t}^{L}\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面我们使用`pytorch`进行简洁实现：\n",
    "\n",
    "与之前小节唯一的区别是，现在通过`num_layers`的值来设定隐藏层数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, num_layers = len(vocab), 256, 2\n",
    "num_inputs = vocab_size\n",
    "device = d2l.try_gpu()\n",
    "lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers)\n",
    "model = d2l.RNNModel(lstm_layer, len(vocab))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于本人资源有限，为了避免花费过长时间训练，将训练代码注释掉。读者若想观看训练效果，可以将`#`去掉，然后执行代码查看。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_epochs, lr = 500, 2\n",
    "# d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4.2 双向（Bi-direction）RNN\n",
    "\n",
    "在之前讲解的RNN当中，我们都是从头往前看得，但是有时候未来的信息很重要，比如你在做英语试卷的完型填空的时候，你往往需要结合**上下文**才能选出正确的答案。不过需要注意的是，并不是所有任务都可以使用双向的神经网络的。\n",
    "\n",
    "![image-20220209144031976](https://s2.loli.net/2022/02/09/qLOUlfkao4evMTr.png)\n",
    "\n",
    "* 取决于过去和未来的上下文，可以填很不一样的词\n",
    "* 目前为止RNN只看过去\n",
    "* 在**完型填空**的时候,我们也可以看未来\n",
    "\n",
    "\n",
    "双向RNN的结构如下所示:\n",
    "![image-20220209144346715](https://s2.loli.net/2022/02/09/8HNcjw2FLsDPCtY.png)\n",
    "\n",
    "可以看到:\n",
    "* 一个**前向RNN隐层**。\n",
    "* 一个**后向RNN隐层**。\n",
    "* **合并**两个隐状态得到输出。\n",
    "\n",
    "其函数依赖可以表示为:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\overrightarrow{\\mathbf{H}}_{t}=\\phi\\left(\\mathbf{X}_{t} \\mathbf{W}_{x h}^{(f)}+\\overrightarrow{\\mathbf{H}}_{t-1} \\mathbf{W}_{h h}^{(f)}+\\mathbf{b}_{h}^{(f)}\\right) \\\\\n",
    "&\\overleftarrow{\\mathbf{H}}_{t}=\\phi\\left(\\mathbf{X}_{t} \\mathbf{W}_{x h}^{(b)}+\\overleftarrow{\\mathbf{H}}_{t+1} \\mathbf{W}_{h h}^{(b)}+\\mathbf{b}_{h}^{(b)}\\right) \\\\\n",
    "&\\mathbf{H}_{t}=\\left[\\overrightarrow{\\mathbf{H}}_{t}, \\overleftarrow{\\mathbf{H}}_{t}\\right] \\\\\n",
    "&\\mathbf{O}_{t}=\\mathbf{H}_{t} \\mathbf{W}_{h q}+\\mathbf{b}_{q}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**关于双向RNN的注意事项:**\n",
    "\n",
    "* 训练\n",
    "\n",
    "![image-20220209144930318](https://s2.loli.net/2022/02/09/cxNvWEnzrkVqQRm.png)\n",
    "\n",
    "* 推理\n",
    "  * 非常**不适合做推理**\n",
    "\n",
    "主要作用是对语义的特征提取，看齐整个句子，比如完型填空。\n",
    "\n",
    "总结：\n",
    "* 双向循环神经网络通过反向更新的隐藏层来利用方向时间信息\n",
    "* 通常用来对序列抽取特征、填空，而不是预测未来"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Pytorch`代码实践:\n",
    "\n",
    "**注意**：下面双向循环神经网络的错误应用, 预测未来不能这样子的！！！（不能未卜先知）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "batch_size, num_steps, device = 32, 35, d2l.try_gpu()\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)\n",
    "# 通过设置“bidirective=True”来定义双向LSTM模型\n",
    "vocab_size, num_hiddens, num_layers = len(vocab), 256, 2\n",
    "num_inputs = vocab_size\n",
    "lstm_layer = nn.LSTM(num_inputs, num_hiddens, num_layers, bidirectional=True)\n",
    "model = d2l.RNNModel(lstm_layer, len(vocab))\n",
    "model = model.to(device)\n",
    "# 训练模型\n",
    "num_epochs, lr = 500, 1\n",
    "# d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}