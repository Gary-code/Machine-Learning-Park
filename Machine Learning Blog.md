# Machine Learning Park

> 机器学习
>
> Gary 哥哥的哥哥
>
> 2021/11/15

## 介绍

> 本专栏主要分**三大版块**，主要用于分享与总结机器学习相关
>
> * **机器学习基础**
> * **深度学习实践**
> * **工业应用**

* 每个核心知识点都包含**知识讲解**和代码实现。
* 本专栏主要目的用于个人学习，亦不可以篇概全，请谅解，有问题可提出。
* 主要代码实现使用python

先来介绍四类角色：

* 领域专家（Domain experts）：知晓机器学习的项目应该部署在那个领域当值，类似于产品经理。
* 数据科学家：类似一个全栈工程师。
* ML专家：制作和优化模型。
* 软件开发工程师（SDE）：产品的落地，需要维护很多其他管理资源的代码。（运维等）

借用斯坦福[实用机器学习课程](https://c.d2l.ai/stanford-cs329p/syllabus.html#ml-model-recap-i)的PPT来看一下这四类角色的成长：

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/image-1.png)





## 基础理论

> 本专栏主要介绍机器学习基础模型并给出对应python代码的实现

### 1 Linear Regression

> 线性回归

#### 1.1 Linear Algebra

> 线性代数

##### 矩阵与向量

$$
X = \left[\begin{array}{cc}
1402 & 191 \\
1371 & 821 \\
949 & 1437 \\
147 & 1448
\end{array}\right]
$$



> 一般默认都以列向量为研究对象
>
> * 为 $n \times 1$的矩阵

$$
y=\left[\begin{array}{l}
460 \\
232 \\
315 \\
178
\end{array}\right]
$$



##### 运算

* 矩阵乘法

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/20211119111147.png)

* 矩阵乘法的特征
  * 不满足交换律
  * 满足结合律

  $$
  A \times B \neq B \times A  \\
  A \times B \times C = A \times (B \times C)
  $$

  

* 单位矩阵： Identity Matrix

$$
I_{4 \times 4} = \left[\begin{array}{llll}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{array}\right]
$$


$$
AA^{-1} = A{-1}A = I \\
AI = IA = A
$$

##### 逆与转置

* 矩阵的逆：
  * 如矩阵𝐴是一个𝑚 × 𝑚矩阵（方阵），如果有逆矩阵，则：$ 𝐴𝐴^{-1}$ = $𝐴^{−1}𝐴$ = 𝐼

* 矩阵的转置：

  * $$
    \left|\begin{array}{ll}
    a & b \\
    c & d \\
    e & f
    \end{array}\right|^{T}=\left|\begin{array}{lll}
    a & c & e \\
    b & d & f
    \end{array}\right|
    $$

  * 基本性质
    $$
    \begin{aligned}
    &(A \pm B)^{T}=A^{T} \pm B^{T} \\
    &(A \times B)^{T}=B^{T} \times A^{T} \\
    &\left(A^{T}\right)^{T}=A \\
    &(K A)^{T}=K A^{T}
    \end{aligned}
    $$
    

#### 1.2 线性回归模型

##### 表达式

$$
Y = WX + b
$$

$w$为变量$X$的系数，$b$为偏置项。

##### 损失函数

> Loss Function -- MSE

$$
J =\frac{1}{2m}\sum_{i=1}^{m}(y^i - y)^2
$$

$m$为样本的个数

##### 模型

Hypothesis:      $\quad h(X)=b+WX$

Parameters:         $W, b$

Cost Function: $\quad J=\frac{1}{2 m} \sum_{i=1}^{m}\left(h\left(x^{(i)}\right)-y^{(i)}\right)^{2}$

Goal:            	$\quad \operatorname{minimize}_{b, W} J$



##### 求解

* 梯度下降算法

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/image-20210714205526599.png)

在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新$𝜃_0$和$𝜃_1$ ，当 𝑗 = 0 和𝑗 = 1时，会产生更新，所以你将更新$𝐽(𝜃_0)$和$𝐽(𝜃_1)$。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新$𝜃_0$和$𝜃_1$，我的意思是在这个等式中，我们要这样更新：$𝜃_0:= 𝜃_0$ ，并更新$𝜃_1:= 𝜃_1$。实现方法是：你应该计算公式右边的部分，通过那一部分计算出$𝜃_0$和$𝜃_1$的值，然后同时更新$𝜃_0$和$𝜃_1$。

* $\alpha$是学习率，用来控制下降你要迈出多大的步子
* 完成一轮之后，更新两个系数$𝜃_0:= 𝜃_0$ ，$𝜃_1:= 𝜃_1$
  * **记住做完一轮才更新，不要一个一个系数轮着来更新**

* 如果𝑎太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果𝑎太小的话，可能会很慢，因为它会一点点挪动，它会需要很多步才能到达全局最低点。

* 如果𝑎太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/image-20210714211745067.png)

* 批量梯度下降
  * 指的是在梯度下降的每一步中，它是指在**每一次迭代时**使用**所有样本**来进行梯度的更新。

$$
\theta_j := \theta_j - \alpha  \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}
$$

对比随机梯度下降

* **每次迭代**使用**一个样本**来对参数进行更新。使得训练速度加快。
* $repeat${
      for $i=1,...,m${

$$
\theta_j := \theta_j -\alpha (h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}  (for j =0,1)
$$

​		}
 }

##### 进阶

* 尺度缩放

在我们面对多维特征问题的时候，**我们要保证这些特征都具有相近的尺度**（范围类似），这将帮助梯度下降算法更快地收敛。
$$
X_𝑛 = \frac{X_n-\mu_n}{s_n}
$$
其中 $𝜇_𝑛$是平均值，$𝑠_𝑛$是标准差(即$max - min$)。



* 学习率 $\alpha$
  * 通常可以考虑尝试些学习率：$\alpha = 0.01, 0.03 ,0.1, 0.3 ,1, 3, 10$



* 正规方程

> normal Equation

$$
𝜃 = (𝑋^𝑇𝑋)^{-1}𝑋^𝑇𝑦
$$

使用python实现如下：

```python
import numpy as np
def normalEqn(X, y):
    theta = np.linalg.inv(X.T@X)@X.T@y #X.T@X 等价于 X.T.dot(X)
    return theta
```

**注意**！！：**对于那些不可逆的矩阵**，正规方程方法是不能用的。

在大规模的数据时候**优先使用梯度下降**而非正规方程



* 正则项

$$
J = J_{原} + \lambda \sum_{j=1}^{m}\theta_j^2\\
J_{原} = \frac{1}{2 m} \sum_{i=1}^{m}\left(h\left(x^{(i)}\right)-y^{(i)}\right)^{2}
$$

为了防止过拟合。



### 2 Logistic Regression & Softmax

#### 2.1 Logistic Regression

> 逻辑回归
>
> * **这是解决分类问题而不是回归问题的！**

> 代码文件说明

| 文件名                        | 说明                          |
| ----------------------------- | ----------------------------- |
| logistic_numpy.ipynb          | 逻辑回归实现（使用a9a数据集） |
| softmax_pytorch_version.ipynb | softmax实现                   |



##### 模型构建

* 模型假设

模型的假设是： $ℎ_𝜃(𝑥) = 𝑔(𝜃^𝑇𝑋) $其中： 𝑋 代表特征向量 𝑔 代表逻辑函数（**logistic** **function**)是一个常用的逻辑函数为 **S** 形函数（**Sigmoid function**），公式为：$ 𝑔(𝑧) = \frac{1}{1+𝑒^{−𝑧} }$

```python
import numpy as np
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

* 函数图像

  ![image](https://camo.githubusercontent.com/f3c61b86afee88892afd380ea1f172a358f639cb825d505c506584107384f2a4/68747470733a2f2f7778342e73696e61696d672e636e2f6c617267652f30303633304465666c7931673470766b32637461746a333063773062363379712e6a7067)

* 举个例子：

如果对于给定的𝑥，通过已经确定的参数计算得出$ℎ_{\theta}(𝑥) = 0.7$，则表示有 70%的几率𝑦为正向类，相应地𝑦为负向类的**几率为 1-0.7=0.3**

* 判断边界

当$ℎ_𝜃(𝑥) $>= 0.5时，预测 𝑦 = 1。 

当$ℎ_𝜃(𝑥) $< 0.5时，预测 𝑦 = 0 。

又 $𝑧 = 𝜃^𝑇𝑥$ ，即：

$𝜃^𝑇𝑥$ >= 0 时，预测 𝑦 = 1 

$𝜃^𝑇𝑥$ < 0 时，预测 𝑦 = 0

* 损失函数

对于线性回归模型，我们定义的损失函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将$ℎ_𝜃(𝑥) = \frac{1}{1+𝑒^{1−𝜃^𝑇𝑋}}$ 

代入到这样定义了的损失函数中时，**我们得到的损失函数将是一个非凸函数（non-convexfunction）。**

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/99d365930166c7a1c19da7e6c818a13.jpg)

这意味着我们的损失函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。

因此我们需要重新定义损失函数：
$$
\operatorname{Cost}\left(h_{\theta}(x), y\right)=\left\{\begin{aligned}
-\log \left(h_{\theta}(x)\right) & \text { if } y=1 \\
-\log \left(1-h_{\theta}(x)\right) & \text { if } y=0
\end{aligned}\right. \\
$$

$$
J(\theta)=\frac{1}{2m}\sum_{i=1}^{m}Cost(h_\theta(x), y)
$$

```python
import numpy as np
def cost(theta, X, y):
    theta = np.matrix(theta)
 	X = np.matrix(X)
    y = np.matrix(y)
    first = np.multiply(-y, np.log(sigmoid(X* theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X* theta.T)))
    return np.sum(first - second) / (len(X))
```

> 下面我们对损失函数进行优化

合并上面的式子可以得到：
$$
𝐶𝑜𝑠𝑡(ℎ_𝜃(𝑥), 𝑦) = −𝑦 × 𝑙𝑜𝑔(ℎ_𝜃(𝑥)) − (1 − 𝑦) × 𝑙𝑜𝑔(1 − ℎ_𝜃(𝑥))
$$


* 梯度下降算法求解



> 当然除了**SGD**（梯度下降算法）之外，还有其他的求解方法，但这里不做过多介绍。

![](https://raw.githubusercontent.com/Gary-code/Machine-Learning-Park/files/blogImgs/image-20210721000458630.png)

#### 2.2 softmax与多分类问题

> 实际上Softmax回归也是一种**分类算法**，对比**逻辑回归**：
>
> * 从二元分类变成多输出分类

##### 模型构建

* 有效编码

> 这里我们以独热编码（one-hot coding）来举例

$$
\begin{aligned}
&\mathbf{y}=\left[y_{1}, y_{2}, \ldots, y_{n}\right]^{\top} \\
&y_{i}=\left\{\begin{array}{l}
1 \text { if } i=y \\
0 \text { otherwise }
\end{array}\right.
\end{aligned}
$$

* 无校验比例

最大值最为预测结果：
$$
\hat{y}=\underset{i}{\operatorname{argmax}} o_{i}
$$

* 校验比例（softmax）

  * 输出匹配概率

    * 非负
    * 和为1

    $$
    \begin{aligned}
    &\hat{\mathbf{y}}=\operatorname{softmax}(\mathbf{o}) \\
    &\hat{y}_{i}=\frac{\exp \left(o_{i}\right)}{\sum_{k} \exp \left(o_{k}\right)}
    \end{aligned}
    $$

* 损失函数

  > 交叉熵

  $$
  l(\mathbf{y}, \hat{\mathbf{y}})=-\sum y_{i} \log \hat{y}_{i}=-\log \hat{y}_{y}
  $$

  其梯度就是真实概率和预测概率的区别
  $$
  \partial_{o_{i}} l(\mathbf{y}, \hat{\mathbf{y}})=\operatorname{softmax}(\mathbf{o})_{i}-y_{i}
  $$

* 总结

  * Softmax回归是一 个多类分类模型
  * 使用Softmax操作子得到每个类的预测置信度
  * 使用交叉熵来来衡量预测和标号的区别



### 3 SVM

> 支持向量机
>
> * 对比与logistic回归和神经网络，SVM在非线性方程很有优势！

​	为了解释一些数学知识， 后续博客将用𝑧 表示$\theta^𝑇𝑥$。

#### 模型构建

* 引入

​	如果我们用一个新的代价函数来代替，即这条从 0 点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为$cos𝑡_1(𝑧)$，同时，右边函数我称它为$cos𝑡_0(𝑧)$。这里的下标是指在代价函数中，对应的 𝑦 = 1 和 𝑦 = 0 的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。

![](https://i.loli.net/2021/11/24/rDki8h7n2BRyfFJ.png)

* 损失函数

$$
\min _{\theta} C \sum_{i=1}^{m}\left[y^{(i)} \operatorname{cost}_{1}\left(\theta^{T} x^{(i)}\right)+\left(1-y^{(i)}\right) \operatorname{cost}_{0}\left(\theta^{T} x^{(i)}\right)\right]+\frac{1}{2} \sum_{i=1}^{n} \theta_{j}^{2}
$$

当$𝜃^𝑇𝑥$大于或者等于 0 时，或者等于 0 时，所以学习参数𝜃就是支持向量机假设函数的形式。那么，这就是支持向量机数学上的定义。



* 加入正则项

$$
\min _{\theta} C \sum_{i=1}^{m}\left[y^{(i)} \cos t_{1}\left(\theta^{T} x^{(i)}\right)+\left(1-y^{(i)}\right) \operatorname{cost}_{0}\left(\theta^{T} x^{(i)}\right)\right]+\frac{1}{2} \sum_{i=1}^{n} \theta_{j}^{2}
$$

**支持向量机所做的是它来直接预测𝑦的值等于 1，还是等于 0。**



#### 深入探讨

* 大边界

  这是我的支持向量机模型的代价函数，在左边这里我画出了关于𝑧的代价函数$cos𝑡_1(𝑧)$，此函数用于正样本，而在右边这里我画出了关于𝑧的代价函数$cos𝑡_0(𝑧)$，横轴表示𝑧，现在让我们考虑一下，最小化这些代价函数的必要条件是什么。如果你有一个正样本，𝑦 = 1，则只有在𝑧 >= 1时，代价函数$cos𝑡_1(𝑧)$才等于 0。



​	具体而言，我接下来会考虑一个特例。我们将这个常数𝐶设置成一个非常大的值。**比如我们假设𝐶的值为 100000 或者其它非常大的数，**然后来观察支持向量机会给出什么结果？



​	**如果 𝐶非常大**，则最小化代价函数的时候，我们将会很希望找到一个使第一项为 0 的最优解。
$$
\min _{\theta} C \sum_{i=1}^{m}\left[y^{(i)} \cos t_{1}\left(\theta^{T} x^{(i)}\right)+\left(1-y^{(i)}\right) \cos t\left(\theta^{T} x^{(i)}\right)\right]+\frac{1}{2} \sum_{i=1}^{n} \theta_{j}^{2}
$$
![](https://i.loli.net/2021/11/27/8kjZMh7biIfcFRT.jpg)

​	黑线看起来是更稳健的决策界。这个距离叫做间距(**margin**)。

* 最小化代价函数

$\min \frac{1}{2} \sum_{j=1}^{n} \theta_{j}^{2}$ s.t 

$\left\{\begin{array}{c}\theta^{T} x^{(i)} \geq 1 \text { if } y^{(i)}=1 \\ \theta^{T} x^{(i)} \leq-1 i f y^{(i)}=0\end{array}\right.$

​	但很多时候一个异常值会影响你的决策边界，而如果正则化参数𝐶，设置的非常大，它将决策界，从黑线变到了粉线。

$C = 1 / \lambda$

* 𝐶 较大时，相当于 $\lambda$ 较小，可能会导致过拟合，**高方差**(过拟合)。
* 𝐶 较小时，相当于  $\lambda$  较大，可能会导致低拟合，**高偏差**（欠拟合）。



#### Kernel

> 核函数

* 假设我们的模型

$$
h_\theta(x) = \theta_{0}+\theta_{1} x_{1}+\theta_{2} x_{2}+\theta_{3} x_{1} x_{2}+\theta_{4} x_{1}^{2}+\theta_5x_2^2
$$

我们使用新的特征$f$来替换：
$$
f_1 = x_1, f_2 = x_2, f3 = x_1x_2, f4 = x_1^2, f5 = x_2^2
$$

* 根据**近似程度**选取$f$

给定一个训练实例 𝑥 ，我们利用 𝑥 的各个特征与我们预先选定的**地标**(**landmarks**)$𝑙^{(1)}, 𝑙^{(2)}, 𝑙^{(3)}$的近似程度来选取新的特征$𝑓_1, 𝑓_2, 𝑓_3$
$$
f_1 = similarity(x, l^{(1)}) = e ^{\left(-\frac{\left\|x-l^{(1)}\right\|^{2}}{2 \sigma^{2}}\right)}\\
其中: \left\|x-l^{(1)}\right\|^{2}=\sum_{j=1}^{n}\left(x_{j}-l_{j}^{(1)}\right)^{2}
$$
$similarity(x, l^{(n)})$就是**核函数**，这里应该叫为**高斯核函数**。



* 直观解释

  * 当$x$和$l$的距离近似为0，这$e^{-0} = 1$
  * 当它们距离较远时候，$e^{大数} = 0$

  

* **细节补充**

> 一般情况下当训练数据集样本数为$m$的时候，我们地标选取的个数也是$m$

$$
f^{(i)}=\left[\begin{array}{c}
f_{0}^{(i)}=1 \\
f_{1}^{(i)}=\operatorname{sim}\left(x^{(i)}, l^{(1)}\right) \\
f_{2}^{(i)}=\operatorname{sim}\left(x^{(i)}, l^{(2)}\right) \\
f_{i}^{(i)}=\operatorname{sim}\left(x^{(i)}, l^{(i)}\right)=e^{0}=1 \\
\vdots \\
f_{m}^{(i)}=\operatorname{sim}\left(x^{(i)}, l^{(m)}\right)
\end{array}\right]
$$

运用到支持向量机当中：

* 当$\theta^Tf \geq 0$则预测$y=1$，反之为0

* 对应修改代价函数：$\sum_{j=1}^{n=m} \theta_{j}^{2}=\theta^{T} \theta$

* **为了简化运算**，我们将$\theta^TM\theta$代替$\theta^{T} \theta$
  * $M$是根据我们选择的核函数而不同的一个矩阵



在高斯核函数之外我们还有其他一些选择，如：

* 多项式核函数（**Polynomial Kerne**l）
* 字符串核函数（**String kernel**）
* 卡方核函数（ **chi-square kernel**）
* 直方图交集核函数（**histogram intersection kernel**）



#### 对比逻辑回归

> $m$为样本数量, $n$为特征数

1. 如果相较于$m$ 而言，$n$ 要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。
2. 如果 $n$ 较小，而且 $m$ 大小中等，例如 $n$ 在 1-1000 之间，而 $m$ 在 10-10000 之间，使用带高斯核函数的支持向量机。
3. 如果 $n$ 较小，而 $m$ 较大，例如 $n$在 1-1000 之间，而 $m$ 大于 50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。

   **值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢**，选择支持向量机的原因主要在于它的代价函数是**凸函数**，不存在局部最小值。 

### 4 Ensemble Method

> 集成学习

代码说明：

| 文件名              | 说明                                  |
| ------------------- | ------------------------------------- |
| random_forest.ipynb | 随机森林sklearn实现（使用iris数据集） |
|                     |                                       |
|                     |                                       |
|                     |                                       |
|                     |                                       |

什么是集成学习？

* 结合几个基本模型，生成一个更好的预测模型
* 主要方法：Bagging、Boosting

![](https://i.loli.net/2021/11/30/mUQdz3GVhDZP5xu.jpg)

* Bootstraping：有放回采样

* Bagging：有放回采样$n$个样本

  通过bootstrap采样获得$T$个采样集

  分别通过样本集训练$T$个基础学习器

  * 对于分类问题：选票最多的类别成为最后一个类别。
  * 对于回归问题：最终的输出是每个基础学习器的平均输出。

  

本章节我们将围绕6种集成学习模型算法来进行讲解：

* 决策树
* AdaBoost
* 随机森林
* GBDT
* XGBoost
* LGBM



#### 4.1 决策树

> 决策树是一种有监督的机器学习算法，可用于**分类**和**回归**问题。

通过一个银行决定是否给用户贷款例子来看一下决策树是如何运作的：

![img](https://img2020.cnblogs.com/other/1981858/202006/1981858-20200618202354959-1195967773.jpg)

因此，决策树根据数据中的一组特征属性（在本例中为信用历史（**Credit History**）、收入（**Income**）和贷款金额（**Loan Amount**））做出一系列决策。

##### 决策树生成算法

> 算法伪代码如下：

![](https://s2.loli.net/2021/12/05/Ox8hKjZBt42kqmY.png)

​	但在很多实际问题当中，数据的某些属性值是对决策**并不重要**或者**毫不相关**。为此我们要对**特征的好坏**进行辨别即**属性选择**。

​	选择属性的算法有很多，其中我们可以使用以下指标来度量：

* 信息增益
* 增益率
* 基尼指数

> 给定带有正类和负类的数据集$D$
>
> * $p_+$为正类占总样本的比例
> * $p_-$为正类占总样本的比例

在讲解**属性选择**方法前，先了解**信息熵**的相关知识

##### **信息熵**（Entropy）

​	描述任意实例集合的**纯度**（purity）

​	**纯度越高**，$Entropy$**值越小**

* 对于二元分类问题

​	其公式为：
$$
Entropy(D) = -p_{+} \log _{2} p_{+}-p_{-} \log _{2} p_{-}
$$


​	如果值为0，则表示$D$中所有样本都属于同一个标签。（相同类别）

​	因为$(p_-) + (p_+) = 1$，所以$Entropy(D)-p_+$函数图像为：

![](https://s2.loli.net/2021/12/05/LwMIRmoTV6gqDt5.png)

* 对于多分类问题
  $$
  \operatorname{Entropy}(D) = \sum_{n=1}^{c}-p_{i} \log _{2} p_{i}
  $$
  $p_i$为第$i$类样本所占总样本的比例

##### **信息增益**（Information gain）

信息增益反映的是通过属性 $𝐴$ 划分训练集 $𝐷$ 能够带来的纯度提升量，记为$Gain(𝐷, 𝐴)$ 

* $Gain$值**越大**，意味着分后的纯度**提升越大**，属性 $𝐴$ 的划分**效果越好**。

其公式如下：
$$
\operatorname{Gain}(D, A)=\operatorname{Entropy}(D)-\sum_{j=1}^{v} \frac{\left|D_{j}\right|}{|D|} \operatorname{Entropy}\left(D_{j}\right)
$$
其中$D_j$是数据集$D$划分成$v$个的子集。

我们目标是希望挑选出具有尽可能好的划分效果的属性$A$ 。即我们希望属性$A$划分过后的子集应该尽可能的纯净，$Entroy(D_j)$越小越好。因此上面式子第二项就是$A$属性划分过后信息熵的**数学期望**。

实际上，式子等价于：
$$
\text { Entropy }(D)-\text { Entropy }_{A}\left(D_{j}\right)
$$


> 计算例子：

![img](https://s2.loli.net/2021/12/05/MGKlB4fVsdQP5wD.png)

将数据二值化：

![img](https://s2.loli.net/2021/12/05/Tjfni6zv1UHlN3V.png)

计算：

![](https://s2.loli.net/2021/12/05/1oOJBxXYRkLITDj.png)

##### 增益率

> 如果将类似**样本标识符**当成属性来计算增益率，会带来一些问题。

由于信息增益挑选属性总是趋于选择取值更大的属性，我们可以使用增益率来**减少**信息增益带来的一些影响。

公式如下：
$$
\operatorname{Gain\_ratio}(D, A)=\frac{\operatorname{Gain}(D, A)}{\operatorname{IV}(A)}
$$
其中
$$
I V(A)=-\sum_{j=1}^{v} \frac{\left|D_{j}\right|}{|D|} \log _{2} \frac{\left|D_{j}\right|}{|D|}
$$
$IV(A)$是属性$A$的**固有属性**，表示属性$A$的可能取值数量，数量越多，$IV(A)$的值越大。



但增益率可能会导致倾向于选择可取值更少的一些属性，因此我们一般处理步骤如下：

1. 先从$D$划分属性中找出**信息增益高于平均水平**的属性。
2. 然后从中选择**增益率高**的属性。



##### 基尼系数

* 基尼值

$$
Gini(D)=\sum_{k=1}^{K} p_{k}\left(1-p_{k}\right)=1-\sum_{k=1}^{K} p_{k}^{2}
$$

其中$D$有$K$个类，$p_k$为第$k$个类样本的频率。

$Gini(D)$的值**越高**，数据集$D$**越混乱**

其**基尼系数**表达式如下：
$$
\operatorname{Gini\_index}(D, A)=\sum_{j=1}^{v} \frac{\left|D_{j}\right|}{|D|} \operatorname{Gini}\left(D_{j}\right)
$$
基尼系数**越小**，数据集**越纯净**，划分效果**越好**。

因此，在实践中选择**基尼指数最小**的属性作为最优划分属性。







#### 4.2 随机森林

> 随机森林使用具有随机结构的决策树

随机森林是以决策树为基础学习器的bagging算法的扩展

* Bagging：

​	Bagging策略可以帮助我们产生不同的数据集。从样本集（假设样本集$m$个数据点）中重采样选出$n$个样本（有放回的采样，样本数据点个数仍然不变为$N$），对这$n$个样本建立分类器（ID3、C4.5、CART、SVM、LOGISTIC），重复以上两步$m$次，获得$m$个分类器，最后根据这$m$个分类器的投票结果，决定数据属于哪一类。



* 随机森林

随机森林在**bagging的基础上更进一步**：

1.  确定基决策树的数量 $N$。我们可以通过调整树的规模来调整随机森林的预测效果。
2.  ==**样本的随机**==：利用自助采样法（bootstrap sampling）我们可以将样本数据分成**训练集**和**袋外数据**。
3.  ==**特征的随机**==：从所有属性中随机选取$K$​个属性，选择**最佳分割属性**作为节点建立CART决策树。（**这里面也可以是其他类型的分类器，比如SVM、Logistics**）重复这一过程直到满足我们设定的停止条件，得到一棵基决策树。
4.  估计袋外误差，我们可以利用袋外数据对生成的决策树计算出袋外误差。
5.  **重复过程 2 到 4**，直到得到有$N$**棵树**的随机森林。



如下图所示：

![](https://s2.loli.net/2021/12/05/gvoL96ZFa1DMEQu.jpg)

* 简单例子解释:

  根据已有的训练集已经生成了对应的随机森林，随机森林如何利用某一个人的年龄（Age）、性别（Gender）、教育情况（Highest  Educational Qualification）、工作领域（Industry）以及住宅地（Residence）共5个**特征**来预测他的收入层次。

  **收入层次：**

  Level 1 : 小于 $40,000

  Level 2: $40,000 – 150,000

  Level 3: 大于 $150,000

随机森林中每一棵树都可以看做是一棵**CART**（分类回归树），这里假设森林中有5棵CART树，总特征个数$N$=5，这里取$m$=1

> 这里假设每个CART树对应一个不同的特征

要预测的某测试样本的信息如下：

| 特征                               | 值             |
| ---------------------------------- | -------------- |
| Age                                | 35 years old   |
| Gender                             | Male           |
| Highest Educational  Qualification | Diploma holder |
| Industry                           | Manufacturing  |
| Residence                          | Metro          |

根据上面五棵CART树的分类结果，我们可以针对这个人的信息建立收入层次的分布情况：

![](https://i.loli.net/2021/11/30/dWQAyLeIUSnEFqg.png)

因此我们可以得出结论：

​	这个人的收入层次70%是一等，大约24%为二等，6%为三等，所以最终认定该人属于一等收入层次。



**与决策树之间对比：**

 对于一个测试数据，**将它投入到随机森林中的不同决策树中，会得到不同的测试结果**。若问题是一个分类问题，则可以通过求众数来得出测试数据的类别；若问题是一个回归问题，则可以通过求平均值得出测试数据的值。

* 随机森林对比决策树，具有更强的分割能力。
* 解决决策树泛化能力弱的缺点。

#### 4.3 AdaBoost（Adaptive Boosting）

​	在了解完决策树与随机森林过后，下面我们介绍AdaBoost模型。

与随机森林不一样，AdaBoost是Boosting算法中的一个显著代表。为此我们简单介绍一下Boosting算法。

##### Boosting

Boosting 算法的特征是个体学习器间存在强依赖关系，个体学习器以串行化方式生成。 

1. 首先依据初始训练集训练出一个基学习器，再根据基学习器的表现对**样本分布进行调整**，对基学习器做错的样本给予更高的权重, 即残差逼近的思想，以**减小偏差**。
2. 根据**调整后**的训练样本训练**下一个基学习器**，如此反复，直到达到预先指定的基学习器数目，再依据基学习器的表现进行结合，从而形成一个具有较好表现。

##### Adaboost

Adaboost的加权模型为**线性加权**，即：
$$
H(x)=\sum_{m=1}^{M} \alpha_{m} h_{m}(x)
$$


其伪代码如下：

![](https://s2.loli.net/2021/12/08/UxiTbVa7ljqk6Pe.png)

完成上面步骤之后，最后输出**模型**：
$$
H(\mathrm{x})=\operatorname{sign}\left(\sum_{t=1}^{T} \alpha_{t} h_{t}(\mathrm{x})\right)
$$
算法解释：

对第$t$个基学习器：

1. 选择并且拟合基学习器$h_t(x)$。
2. 根据拟合的基学习器，加入权重$w_{t}(i)$计算残差$e_t$。
3. 计算基学习器的权重$\alpha_t$。
4. 更新数据权重$w_{t+1}(i)$用于下一个基学习器。

仔细观察，我们可以把步骤4的计算过程改写成：
$$
w_{t+1}(i)= \begin{cases}\frac{w_{t}(i)}{z_{t}} e^{-\alpha_{t}}, & \text { for right predictive sample } \\ \frac{w_{t}(i)}{z_{t}} e^{\alpha_{t}}, & \text { for wrong predictive sample }\end{cases}
$$
同时，我们注意到，当$e_{t} \leq 0.5且\alpha_{t} \geq 0$的时候，$\alpha_{t}=\frac{1}{2} \ln \frac{1-e_{t}}{e_{t}}$随着$e_t$的减小,$\alpha_t$会变大。证明错误率较小的分类器将更为重要。也从中看出AdaBoost模型的合理性。

#### 4.4 GBDT（梯度提升决策树）

梯度提升决策树(GBDT)是一种具有迭代的决策树算法。

与AdaBoost相似，GBDT的关键是，树可以学习之前所有树的所有**结果**和**残差**。

GBDT的原理很简单，就是所有弱分类器的结果相加等于预测值，然后下一个弱分类器去拟合误差函数对预测值的残差(这个残差就是预测值与真实值之间的误差)。当然了，它里面的弱分类器的表现形式就是各棵树。



##### GBDT算法

梯度提升算法如下：

![](https://s2.loli.net/2021/12/08/Cx6ytu5hOTPaB1l.png)

##### GBDT训练过程

> 我今年30岁了，但计算机或者模型GBDT并不知道我今年多少岁，那GBDT如何做呢？

- 它会在第一个弱分类器（或第一棵树中）随便用一个年龄比如20岁来拟合，然后发现误差有10岁；
- 接下来在第二棵树中，用6岁去拟合剩下的损失，发现差距还有4岁；
- 接着在第三棵树中用3岁拟合剩下的差距，发现差距只有1岁了；
- 最后在第四课树中用1岁拟合剩下的残差，完成。
- 最终，四棵树的结论加起来，就是真实年龄30岁（实际工程中，gbdt是计算负梯度，用负梯度近似残差）。

负梯度的计算为：

> 真实值-拟合值

$$
-\left[\frac{\partial l\left(y_{i}, y^{i}\right)}{\partial y^{i}}\right]=\left(y_{i}-y^{i}\right)
$$

每一次拟合的值就是（真实值 - 当前模型预测的值），即残差。



下面通过例子讲解GDBT的**训练过程**

> 简单起见，假定训练集只有4个人：A,B,C,D
>
> * 他们的年龄分别是14,16,24,26。
> * 其中A、B分别是高一和高三学生
> * C,D分别是应届毕业生和工作两年的员工。

如果是用一棵传统的回归决策树来训练，会得到如下图所示结果：

![image-20211209203336915](https://s2.loli.net/2021/12/09/ePH9EFYGgTOlqDd.png)

现在我们使用GBDT来做这件事，由于数据太少，我们限定叶子节点做多有两个，即每棵树都只有一个分枝，并且限定只学两棵树。我们会得到如下图所示结果：

![](https://s2.loli.net/2021/12/09/DXtoF1hmpjgisev.png)

在第一棵树分枝和图1一样，由于A,B年龄较为相近，C,D年龄较为相近，他们被分为左右两拨，每拨用平均年龄作为预测值。



然后拿它们的残差-1、1、-1、1代替A B C D的原值，到第二棵树去学习，第二棵树只有两个值1和-1，直接分成两个节点，即A和C分在左边，B和D分在右边，经过计算（比如A，实际值-1 - 预测值-1 = 残差0，比如C，实际值-1 - 预测值-1 = 0），**此时所有人的残差都是0**。残差值都为0，相当于第二棵树的预测值和它们的实际值相等，则只需把第二棵树的结论累加到第一棵树上就能得到真实年龄了，即每个人都得到了真实的预测值。

- A: 14岁高一学生，购物较少，经常问学长问题，预测年龄A = 15 – 1 = 14
- B: 16岁高三学生，购物较少，经常被学弟问问题，预测年龄B = 15 + 1 = 16
- C: 24岁应届毕业生，购物较多，经常问师兄问题，预测年龄C = 25 – 1 = 24
- D: 26岁工作两年员工，购物较多，经常被师弟问问题，预测年龄D = 25 + 1 = 26

所以，GBDT需要将多棵树的得分累加得到最终的预测得分，且每一次迭代，都在现有树的基础上，增加一棵树去拟合前面树的**预测结果与真实值之间的残差**。



##### GDBT的优缺点

* 优点
  1. **预测阶段**的计算速度快，树与树之间可并行化计算。
  2. 在分**布稠密的数据集**上，泛化能力和表达能力都很好，这使得GBDT在Kaggle的众多竞赛中，经常名列榜首。
  3. 采用决策树作为弱分类器使得GBDT模型具有较好的**解释性**和**鲁棒性**，能够自动发现特征间的高阶关系，并且也**不需要对数据进行特殊的预处理如归一化**等。

* 缺点
  1. GBDT在**高维稀疏的数据集**上，表现不如支持向量机或者神经网络。
  2. GBDT在**处理文本分类特征问题**上，相对其他模型的优势不如它在处理数值特征时明显。
  3. 训练过程需要串行训练，只能在决策树内部采用一些局部并行的手段提高训练速度。

#### 4.5 XGBoost

:rocket: ing...

#### 4.6 LGBM

:rocket:ing...





### 5 聚类（Clustering）

> 本文Github仓库已经同步文章与代码[https://github.com/Gary-code/Machine-Learning-Park/tree/main/5%20Clustering](https://github.com/Gary-code/Machine-Learning-Park/tree/main/5%20Clustering)

> 代码说明：

| 文件名                                                       | 说明                        |
| ------------------------------------------------------------ | --------------------------- |
| [k_means.ipynb](https://github.com/Gary-code/Machine-Learning-Park/blob/main/5 Clustering/k_means.ipynb) | K_Means算法解决文本词汇聚类 |
| [GMM.ipynb](https://github.com/Gary-code/Machine-Learning-Park/blob/main/5 Clustering/GMM.ipynb) | GMM从零开始实现             |
| [corpus_train.txt](https://github.com/Gary-code/Machine-Learning-Park/blob/main/5 Clustering/corpus_train.txt) | 用于K_Means聚类的文本数据集 |



> 如果你有时刻留意我们[项目在github上的地址](https://github.com/Gary-code/Machine-Learning-Park)，你或许会发现从这里开始的代码会逐渐偏重于**理论探讨**和**场景应用**。主要为了更好的将我们所讲的理论知识用于实践当中。

由于当前处于基础知识讲解版块，我们尽量控制为**简单的实践**。真正工业级别的实践，我们将在项目第二版块（**当下应用**）陆续为大家揭晓更多内容，敬请期待:rocket:

> 有错误欢迎读者联系我指正。

与前面讲解的算法模型不一样，聚类是一种**无监督学习**(**Unsupervised Learning**)的方式。

#### 5.1 无监督学习

与有监督学习最大的不同，就是学习的数据是**没有标签**的。

![](https://s2.loli.net/2021/12/09/HeQn2uLdSsVo5RO.png)

在无监督学习的过程当中，我们需要输入一些没有标签的数据，让算法帮我们找到数据**内在结构**。对于聚类问题而言，这种内在结构就是**类别**。

上图的数据看起来可以分开成为两个点集（**簇**），一个能够找到这两个簇的算法，就是我们这里要说的**聚类算法**。



这里我们将介绍两个聚类算法：

* K-Means（K均值）
* GMM（高斯混合模型）

#### 5.2 K-Means

K-Means算法步骤非常简单，具体过程为下面：

- 首先选择𝐾个随机的点，称为聚类中心（cluster centroids）；
- 对于数据集中的每一个数据，按照距离𝐾个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。
- 计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。
- 重复步骤，直至中心点几乎不再变化。

伪代码：

```python
Repeat {
    for i = 1 to m
    c(i) := index (form 1 to K) of cluster centroid closest to x(i)
    for k = 1 to K
    μk := average (mean) of points assigned to cluster k
}

```



##### 优化目标和损失函数

K-均值最小化问题，是要最小化所有的数据点与其所关联的聚类中心点之间的距离之和，因此 K-均值的代价函数（又称**畸变函数** **Distortion function**）为：
$$
J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)=\frac{1}{m} \sum_{i=1}^{m}\left\|X^{(i)}-\mu_{c^{(i)}}\right\|^{2}
$$
其中$𝜇_{𝑐(𝑖)}$代表与$𝑥^{(𝑖)}$最近的聚类中心点。 



对此我们可以分析出：

* 第一个循环是用于减小$𝑐^{(𝑖)}$引起的代价
* 而第二个循环则是用于减小$𝜇_𝑖$引起的代价。
* 迭代的过程一定会是**每一次迭代都在减小代价函数**，不然便是出现了错误。

##### 初始化问题

由于我们开始选取的K个点是随机的，因此算法有可能会停留在一个**局部最小值**处。

为了解决这个问题，我们通常需要多次运行K-均值算法，每一次都重新进行随机初始化，最后再比较多次运行K-均值的结果，选择**代价函数最小**的结果。

##### 聚类数量选择

另外一个可调节的参数就是K，聚类的数量。我们通常采用“肘部法则”来决定。如果你接触过主成分析法(PCA)，肯定对此不会感到陌生。



所有的数据都会分到一个聚类里，然后计算成本函数或者计算畸变函数$J$。$K$代表聚类数量。

> 下面我们来看一个例子：

![](https://s2.loli.net/2021/12/09/Bz6vwsgeCmALRKc.png)

通过分析，使用**3个类别**来进行聚类是正确的。

#### 5.3 GMM（高斯混合模型）

与K均值算法类似，同样使用了EM算法进行迭代计算。

高斯混合模型假设每个簇的数据都是**符合高斯分布**（正态分布），因此当前数据呈现的分布就是**各个簇**的高斯分布**叠加**在一起的结果。

高斯混合模型的核心思想是，假设数据可以看作从多个高斯分布中生成出来的。

在该假设下，每个单独的分模型都是标准高斯模型:

* 其均值 $\mu_k$ 和方差 $\sigma_k$ 是待估计的参数
* 每个分模型都还有一个参数 $\alpha_k$
* 参数表示为$\theta_k$可以理解为**权重**或生成数据的概率。高斯混合模型的公式为：

$$
P(x \mid \theta)=\sum_{k=1}^{K} \alpha_{k} \phi\left(x \mid \theta_{k}\right)
$$

对于上面三个参数的求解，我们开始的想法或许是采用概率统计学当中的**最大似然估计**的方法。遗憾的是，此问题中直接使用最大似然估计，得到的是一 个**复杂的非凸函数**，目标函数是和的对数，难以展开和**对其求偏导**，其表达式如下：
$$
\log L(\theta)=\sum_{j=1}^{N} \log P\left(x_{j} \mid \theta\right)=\sum_{j=1}^{N} \log \left(\sum_{k=1}^{K} \alpha_{k} \phi\left(x \mid \theta_{k}\right)\right)
$$


这种情况下可以采用**EM算法**来求解。

##### EM算法

1. E-step：求期望 $E\left(\gamma_{j k} \mid X, \theta\right)$ for all $j=1,2,...N;k=1,2,...,K$。
2. M-step：求极大，计算新一轮迭代的模型参数。

EM算法是在最大化目标函数时：

1. 固定一个变量使整体函数变为**凸优化函数**。
2. 求导得到**最值**。
3. 利用最优参数更新被固定的变量，进入下一个循环。

对于GMM：

首先，随机**初始化**参数的值。然后，重复下述两步，直到收敛。

- E步骤。依据当前参数，计算每个数据$j$来自子模型$k$的可能性。

$$
\gamma_{j k}=\frac{\alpha_{k} \phi\left(x_{j} \mid \theta_{k}\right)}{\sum_{k=1}^{K} \alpha_{k} \phi\left(x_{j} \mid \theta_{k}\right)}, j=1,2, \ldots, N ; k=1,2, \ldots, K
$$



- M步骤。使用E步骤估计出的概率，来改进每个分模型的均值，方差和权重。如下所示，注意：每计算完一个值就**马上更新**！

$$
\mu_{k}=\frac{\sum_{j}^{N}\left(\gamma_{j k} x_{j}\right)}{\sum_{j}^{N} \gamma_{j k}}, k=1,2, \ldots, K
$$

用这一轮更新后的$\mu_k$：
$$
\sigma_{k}=\frac{\sum_{j}^{N} \gamma_{j k}\left(x_{j}-\mu_{k}\right)\left(x_{j}-\mu_{k}\right)^{T}}{\sum_{j}^{N} \gamma_{j k}}, k=1,2, \ldots, K
$$

$$
\alpha_{k}=\frac{\sum_{j=1}^{N} \gamma_{j k}}{N}, k=1,2, \ldots, K
$$

**重复**E-M过程，**直到收敛**。

> 举一个例子：

高斯混合模型是一个生成式模型。可以这样理解数据的生成过程，假设一个最简单的情况，即只有两个一维标准高斯分布的分模型*N*(0,1)和*N*(5,1)，其权重分别为0.7和0.3。

那么，在生成第一个数据点时，先按照权重的比例，随机选择一个分布，比如选择第一个高斯分布，接着从*N*(0,1)中生成一个点，如−0.5，便是第一个数据点。

在生成第二个数据点时，随机选择到第二个高斯分布*N*(5,1)，生成了第二个点4.7。如此循环执行，便生成出了所有的数据点。

也就是说，我们并不知道最佳的K个高斯分布的各自3个参数，也不知道每个数据点究竟是哪个高斯分布生成的。所以每次循环时：

* 先固定当前的高斯分布不变，获得每个数据点由各个高斯分布生成的概率。
* 然后固定该生成概率不变，根据数据点和生成概率，获得一个组更佳的高斯分布。
* 循环往复，直到参数的不再变化，或者变化非常小时，便得到了比较合理的一组高斯分布。

与K-Means相比，GMM同样需要指定K类别，且都往往只能收敛于局部最优。

但其有点就是，引入了概率的知识：

* 可以给出一个样本属于某类的概率是多少。
* 不仅仅可以用于聚类，还可以用于概率密度的估计。
* 并且可以用于生成新的样本点。

#### 5.4 参考资料

![](https://s2.loli.net/2021/12/09/sI2RjpVSxB8gDzl.png)

![](https://s2.loli.net/2021/12/09/m2e1foRCl7Wvihu.png)

![](https://s2.loli.net/2021/12/09/mTPCaWMlDVF3nek.png)

### 6 KNN (K近邻)

用官方的话来说，所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，**在训练数据集中找到与该实例最邻近的K个实例（K个邻居），这K个实例的多数属于某个类，就把该输入实例分类到这个类中。**

下面举一个简单的例子：

![img](https://s2.loli.net/2021/12/11/CZms5KTPyDBwvhp.png)



图中的那个**绿色的圆**所标示的数据则是**待分类**的数据。KNN就是解决这个分类问题的

* 如果K=3，绿色圆点的最近的3个邻居是2个红色小三角形和1个蓝色小正方形，少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于红色的三角形一类。

* 如果K=5，绿色圆点的最近的5个邻居是2个红色三角形和3个蓝色的正方形，还是少数从属于多数，基于统计的方法，判定绿色的这个待分类点属于蓝色的正方形一类。

**当无法判定当前待分类点是从属于已知分类中的哪一类时，我们可以依据统计学的理论看它所处的位置特征，衡量它周围邻居的权重，而把它归为(或分配)到权重更大的那一类。这就是K近邻算法的核心思想。**



#### 距离公式

* **欧氏距离**：
  $$
  d(x, y)=\sqrt{\left(x_{1}-y_{1}\right)^{2}+\left(x_{2}-y_{2}\right)^{2}+\ldots+\left(x_{n}-y_{n}\right)^{2}}=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}}
  $$

$$
d_{12}=\sqrt{(a-b)(a-b)^{T}}(向量表示)
$$

标准化后的欧式距离:

$标准化后的值 = \frac{( 标准化前的值 － 分量的均值 )}{分量的标准差}$
$$
d_{12}=\sqrt{\sum_{k=1}^{n}\left(\frac{x_{1 k}-x_{2 k}}{s_{k}}\right)^{2}}
$$


* **曼哈顿距离**

> 类似一个十字路口拐弯

$$
\left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right|
$$

对于两个n维向量a，b:
$$
d_{12}=\sum_{k=1}^{n} \mid x_{1 k}-x_{2 k} \mid
$$
当然还有很多类型的距离公式，有兴趣的读者可以自行查阅相关资料。



#### K值选择

相信看完上面的简单例子，大家都知道$K$值的选择对分类的结果是有较大影响的，这里我们探讨一下如何选择$K$值。

1. 如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，**K值的减小就意味着整体模型变得复杂，容易发生过拟合；**
2. 如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且**K值的增大就意味着整体的模型变得简单。**
3. K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。

在实际应用中，K值一般取一个比较小的数值，**例如采用交叉验证法（一部分样本做训练集，一部分做验证集）来选择最优的K值。**

#### 算法过程

1. 计算测试样本和训练样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）。
2. 对上面所有的距离值进行排序。
3. 选前$k$个最小距离的样本。
4. 根据这$k$个样本的标签进行投票，得到最后的分类类别。



### 7 Bayes Network

> 贝叶斯网络

#### 7.1 概率图模型

​	**概率图模型**是用图来表示变量概率依赖关系的理论，结合概率论与图论的知识，利用图来表示与模型**有关的变量的联合概率分布**。

​	概率图中的节点分为隐含节点和观测节点，边分为有向边和无向边。从概率论的角度，节点对应于随机变量，边对应于随机变量的依赖或相关关系，其中**有向边表示单向的依赖，无向边表示相互依赖关系**。

​	概率图模型分为**贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）**两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表 示成一个无向图的网络结构。

更加详细的来看，概率图模型主要分为：

* 朴素贝叶斯模型
* 最大熵模型
* 隐马尔可夫模型
* 条件随机场
* 主题模型

......

#### 7.2 贝叶斯定理

谈到贝叶斯网络，不得不说的就是贝叶斯定理了，其公式为：
$$
P(A \mid B)=\frac{P(A \cap B)}{P(B)}
$$
先验概率为$P(A)$或者$P(B)$



#### 7.3 贝叶斯网络

**贝叶斯中的基本概念**

- **先验概率：**就是因变量（二分法）在数据集中的比例，$P(A)$。
  - 这是在你没有任何进一步的信息的时候，是对分类能做出的最接近的猜测。
- **似然估计：**似然估计是在其他**一些变量的给定**的情况下，一个观测值被分类为1的概率。
  - 例如，“FREE”这个词在以前的垃圾邮件使用的概率就是似然估计。
- **边际似然估计：**边际似然估计就是，“FREE”这个词在任何消息中使用的概率。

贝叶斯网络(Bayesian network)，又称信念网络(Belief Network)，或有向**无环图模型**(directed acyclic graphical model)，是一种概率图模型，于1985年由Judea Pearl首先提出。它是一种模拟人类推理过程中因果关系的不确定性处理模型，其网络拓朴结构是一个**有向无环图**(DAG)。如下图所示：

![](https://s2.loli.net/2021/12/17/6jQXz8SHlLMIkYK.png)

计算方法如下所示:

![](https://s2.loli.net/2021/12/17/M2HisZQhcWIFXg4.png)



**朴素贝叶斯**

> 经典的机器学习算法之一，也是为数不多的基于概率论的分类算法。朴素贝叶斯原理简单，也很容易实现，多用于**文本分类**，比如**垃圾邮件过滤**。

朴素贝叶斯可以看做是贝叶斯网络的特殊情况：**即该网络中无边，各个节点都是独立的。** 

其基于两个重要的**假设**：

- 一个特征出现的概率与其他特征（条件）独立
- 每个特征同等重要

**朴素贝叶斯优点**：

- 算法逻辑简单,易于实现（算法思路很简单，只要使用贝叶斯公式转化即可！）
- 分类过程中时空开销小（假设特征相互独立，只会涉及到二维存储）

**朴素贝叶斯缺点**：

​	理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，在属性个数比较多或者属性之间相关性较大时，分类效果不好。

​	朴素贝叶斯模型(Naive Bayesian Model)的**朴素(Naive)的含义是"很简单很天真"**地假设样本特征彼此独立. 这个假设现实中基本上不存在, 但特征相关性很小的实际情况还是很多的, 所以这个模型仍然能够工作得很好。



#### 7.4 对比其他模型

- **判别模型**(discriminative model)通过求解条件概率分布P(y|x)或者直接计算y的值来预测y。
  * 线性回归（Linear Regression）,逻辑回归（Logistic Regression）,支持向量机（SVM）, 传统神经网络（Traditional Neural Networks）
- **生成模型**（generative model）通过对观测值和标注数据计算**联合概率分布**$P(x,y)$来达到判定估算y的目的。
  * 朴素贝叶斯（Naive Bayes）, 隐马尔科夫模型（HMM）,贝叶斯网络（Bayesian Networks）和隐含狄利克雷分布（Latent Dirichlet Allocation）、混合高斯模型(GMM)



### 8 Markov（马尔科夫模型）

> HMM(隐马尔科夫模型)

隐马尔科夫模型（Hidden Markov Model，以下简称HMM）是比较经典的机器学习模型了，它在**自然语言处理**，**模式识别**等领域得到广泛的应用。

​	当然，随着深度学习的崛起，其逐渐被**RNN，LSTM，Transformer**等神经网络模型替代，但其中的思想仍然非常值得研究者去学习，由于本专栏专注于对基础知识的挖掘，因此对**HMM**会做深入的探究。

#### 8.1 模型基础

使用**HMM**的问题特征：

* 问题基于序列
  * 时间序列
  * 状态序列
* 两类数据
  * 可观测（观测序列）
  * 不可观测（隐藏序列）

> 比如：

​	我现在在打字写博客，我在键盘上敲出来的一系列字符就是**观测序列**，而我实际想写的一段话就是**隐藏序列**，输入法的任务就是从敲入的一系列字符尽可能的猜测我要写的一段话，**并把最可能的词语放在最前面让我选择**，这就可以看做一个HMM模型了。



> 下面我们通过数学形式来表达HMM模型

对于HMM模型，首先我们假设$Q$是所有可能的**隐藏状态的集合**，$V$是所有可能的**观测状态的集合**，即：
$$
Q=\left\{q_{1}, q_{2}, \ldots, q_{N}\right\}, V=\left\{v_{1}, v_{2}, \ldots v_{M}\right\}
$$
其中，$N$是可能的**隐藏状态数**，$M$是所有的可能的**观察状态数**。

对于一个长度为$T$的序列，$I$对应的状态序列, $O$是对应的观察序列，即：
$$
I=\left\{i_{1}, i_{2}, \ldots, i_{T}\right\}, O=\left\{o_{1}, o_{2}, \ldots o_{T}\right\}
$$
其中，任意一个隐藏状态$i_t \in Q$,任意一个观察状态$o_t \in V$



同时HMM模型做出两个重要的假设：

1. 齐次马尔科夫链假设。（**对隐藏状态而言**）即任意时刻的隐藏状态只依赖于它前一个隐藏状态，如果在时刻$t$的隐藏状态是$i_t=q_i$,在时刻$t+1$的隐藏状态是$i_{t+1}=q_{ji}$, 则从时刻tt到时刻$t+1$的HMM状态转移概率$a_ij$可以表示为：
   $$
   a_{i j}=P\left(i_{t+1}=q_{j} \mid i_{t}=q_{i}\right)
   $$
   $a_{ij}$可以组成==**马尔科夫链状态转移矩阵**$==$:
   $$
   A = [a_{ij}]_{N \times N}
   $$

2. 观测独立性假设。（**对于隐藏状态生成观测状态的概率**）即任意时刻的**观察状态**只**仅仅依赖于**当前时刻的**隐藏状态**，这也是一个为了简化模型的假设。

   如果在时刻$t$的隐藏状态是$i_t=q_j$, 而对应的观察状态为$o_t=v_k$, 则该时刻观察状态$v_k$在隐藏状态$q_j$下生成的概率为$b_j(k)$，则：
   $$
   b_{j}(k)=P\left(o_{t}=v_{k} \mid i_{t}=q_{j}\right)
   $$
   $b_j(k)$可以组成==**观测状态生成的概率矩阵**==：
   $$
   B=\left[b_{j}(k)\right]_{N \times M}
   $$

3. 除此意外，对于初始的状态信息，我们还要做出假设。要一组在时刻$t=1$的==**隐藏状态概率分布**==:
   $$
   \Pi=[\pi(i)]_{N} \text { 其中 } \pi(i)=P\left(i_{1}=q_{i}\right)
   $$
   
   
   

   一个HMM模型，可以由隐藏状态初始概率分布$\Pi$, 状态转移概率矩阵$A$和观测状态概率矩阵$B$决定。$\Pi,A$决定状态序列，$B$决定观测序列。因此，HMM模型可以由一个三元组$\lambda$表示如下：
   $$
   \lambda=(A, B, \Pi)
   $$
   

   #### 8.2 HMM例子

   > 例子来源于李航的《统计学习方法》

   假设我们有3个盒子，每个盒子里都有红色和白色两种球，这三个盒子里球的数量分别是：

   | 盒子   | 1    | 2    | 3    |
   | ------ | ---- | ---- | ---- |
   | 红球数 | 5    | 4    | 7    |
   | 白球数 | 5    | 6    | 3    |

​	按照下面的方法从盒子里抽球

* 开始的时候，从第一个盒子抽球的概率是0.2，从第二个盒子抽球的概率是0.4，从第三个盒子抽球的概率是0.4。以这个概率抽一次球后，将球放回。

* 然后从当前盒子转移到下一个盒子进行抽球。规则是：如果当前抽球的盒子是第一个盒子，则以0.5的概率仍然留在第一个盒子继续抽球，以0.2的概率去第二个盒子抽球，以0.3的概率去第三个盒子抽球。

  * 如果当前抽球的盒子是第二个盒子，则以0.5的概率仍然留在第二个盒子继续抽球，以0.3的概率去第一个盒子抽球，以0.2的概率去第三个盒子抽球。
  * 如果当前抽球的盒子是第三个盒子，则以0.5的概率仍然留在第三个盒子继续抽球，以0.2的概率去第一个盒子抽球，以0.3的概率去第二个盒子抽球。

* 如此下去，直到重复三次，得到一个球的颜色的观测序列:
  $$
  O = \{红,白,红\}
  $$

  >  注意在这个过程中，观察者**只能看到球的颜色序列**，却**不能看到球是从哪个盒子**里取出的。

  **观察集合**为$V=\{红，白\}，M=2$,**状态集合**为$Q=\{盒子1，盒子2，盒子3\}，N=3$

  观察序列和状态序列的长度为3

* 初始状态分布为：
  $$
  \Pi = (0.2, 0.4, 0.4)^T
  $$

* 状态转移概率分布矩阵$A$:
  $$
  A=\left(\begin{array}{lll}
  0.5 & 0.2 & 0.3 \\
  0.3 & 0.5 & 0.2 \\
  0.2 & 0.3 & 0.5
  \end{array}\right)
  $$

* 观测状态概率矩阵$B$:
  $$
  B=\left(\begin{array}{ll}
  0.5 & 0.5 \\
  0.4 & 0.6 \\
  0.7 & 0.3
  \end{array}\right)
  $$

#### 8.3 HMM模型特征

**HMM模型观察序列生成**

1. 根据初始状态概率分布$\Pi$生成隐藏状态$i_1$

2. for t from 1 to T
   1. 按照隐藏状态$i_t$的观测状态分布$b_{i_t}(k)$生成观察状态$o_t$
   2.  按照隐藏状态$i_t$的状态转移概率分布产生隐藏状态$i_{t+1}$
3. 所有的$o_t$一起形成观测序列$O=\{o_1,o_2,...o_T\}$



**经典的三个问题**

1） [评估观察序列概率](https://www.cnblogs.com/pinard/p/6955871.html)。需要用到**前向后向算法**。（简单）

2）[模型参数学习问题](https://www.cnblogs.com/pinard/p/6972299.html)。需要用到基于**EM算法**的鲍姆-韦尔奇算法。（难）

3）[预测问题](https://www.cnblogs.com/pinard/p/6991852.html)，也称为解码问题。需要用到基于**动态规划的维特比算法**。（居中）







### 9 EM算法（最大期望算法）

> 在前面[聚类的博客](https://blog.csdn.net/Garyboyboy/article/details/121865540)当中，我们简单的讲解过使用EM算法求解GMM模型的过程，这里我们对EM算法深入进行探讨。

最大期望算法（Expectation-maximization algorithm），是在概率模型中**寻找参数最大似然估计**或者**最大后验估计**的算法，其中概率模型依赖于无法观测的隐性变量。

算法两个核心步骤：

* **E（计算期望）**
  * 利用对隐藏变量的现有估计值，计算其**最大似然估计值**
* **M（最大化）**
  * 最大化在E步上求得的最大似然值来计算参数的值
  * M步上找到的参数估计值被**用于下一个E步骤**计算中，这个过程不断交替进行。
* 简单的一句话表示就是：**知道结果，反推条件**$\theta$

#### 9.1 似然函数

**似然函数**是一种关于统计模型中的参数的函数，表示模型参数中的似然性。**极大似然就相当于最大可能。**

最大似然估计是已经知道了**结果**，然后寻求使该结果出现的可能性最大的**条件**，以此作为**估计值**。

**极大似然函数求解步骤**

> 我们通过一个例子来进行求解分析

假定我们要从10万个人当中抽取100个人来做身高统计，那么抽到这100个人的概率就是：

$L(\theta)=L\left(x_{1}, \ldots, x_{n} \mid \theta\right)=\prod_{i=1}^{n} p\left(x_{i} \mid \theta\right), \theta \in \Theta$

现在，我们的目标就是求解出$\theta$值，使得$L(\theta)$的值最大。

为此我们定义**对数似然函数**，将其变成连加的形式：

$H(\theta)=\ln L(\theta)=\ln \prod_{i=1}^{n} p\left(x_{i} \mid \theta\right)=\sum_{i=1}^{n} \ln p\left(x_{i} \mid \theta\right)$

在本科数学课程当中我们已经学过**偏导数**的求解方法，为此，我们对应求$L(\theta)$对所有参数的偏导数，也就是梯度了，从而$n$个未知的参数，就有$n$个方程，方程组的解就是似然函数的极值点了，最终得到这$n$个参数的值。

**极大似然函数估计值求解步骤如下**：

1. 写出似然函数；
2. 对似然函数取对数，并整理；
3. 求导数，令**导数为0**，得到似然方程；
4. 解似然方程，得到的参数即为所求；

#### 9.2 EM算法求解

> 同样，我们也通过一个例子来讲解EM算法

两枚硬币A和B，假定随机抛掷后正面朝上概率分别为$PA$，$PB$。为了估计这两个硬币朝上的概率，咱们轮流抛硬币A和B，每一轮都连续抛5次，总共5轮：

| 硬币 | 结果       | 统计    |
| ---- | ---------- | ------- |
| A    | 正正反正反 | 3正-2反 |
| B    | 反反正正反 | 2正-3反 |
| A    | 正反反反反 | 1正-4反 |
| B    | 正反反正正 | 3正-2反 |
| A    | 反正正反反 | 2正-3反 |

硬币A被抛了15次，在第一轮、第三轮、第五轮分别出现了3次正、1次正、2次正，所以很容易估计出PA，类似的，PB也很容易计算出来(**真实值**)，如下：

PA = （3+1+2）/ 15 = 0.4 PB= （2+3）/10 = 0.5

问题来了，如果我们**不知道抛的硬币是A还是B**呢（即硬币种类是**隐变量**），然后再轮流抛五轮，得到如下结果：

| 硬币    | 结果       | 统计    |
| ------- | ---------- | ------- |
| Unknown | 正正反正反 | 3正-2反 |
| Unknown | 反反正正反 | 2正-3反 |
| Unknown | 正反反反反 | 1正-4反 |
| Unknown | 正反反正正 | 3正-2反 |
| Unknown | 反正正反反 | 2正-3反 |

> 现在我们的目标没变，还是估计$PA$和$PB$，需要怎么做呢？

显然，此时我们多了一个硬币种类的隐变量，设为z，可以把它认为是一个**5维的向量**$（z1,z2,z3,z4,z5)$，代表每次投掷时所使用的硬币，比如$z1$，就代表第一轮投掷时使用的硬币是A还是B。

- 但是，这个变量$z$不知道，就无法去估计PA和PB，所以，我们必须先估计出$z$，然后才能进一步估计PA和PB。
- 可要估计z，我们又得知道PA和PB，这样我们才能用极大似然概率法则去估计$z$，这不是鸡生蛋和蛋生鸡的问题吗，如何解决呢？

解决方法：

* 先**随机初始化**一个$PA和PB$，用它来估计$z$
* 然后基于$z$，还是按照最大似然概率法则去估计新的$PA$和$PB$
* 然后依次循环，如果新估计出来的$PA和PB$和我们真实值差别很大，继续上一步过程，直到**PA和PB收敛到真实值为止。**

先随便给PA和PB赋一个值，比如： 硬币A正面朝上的概率$PA = 0.2$ 硬币B正面朝上的概率$PB = 0.7$

然后，我们看看第一轮抛掷最可能是哪个硬币。

 如果是**硬币A**，得出3正2反的概率为 :

$0.2 *0.2* 0.2 *0.8* 0.8 = 0.00512$ 

如果是**硬币B**，得出3正2反的概率为:

$0.7 *0.7* 0.7 *0.3* 0.3=0.03087$ 

然后依次求出其他4轮中的相应概率。做成表格如下：

| 轮数 | 若是硬币A        | 若是硬币B        |
| ---- | ---------------- | ---------------- |
| 1    | 0.00512，3正-2反 | 0.03087，3正-2反 |
| 2    | 0.02048，2正-3反 | 0.01323，2正-3反 |
| 3    | 0.08192，1正-4反 | 0.00567，1正-4反 |
| 4    | 0.00512，3正-2反 | 0.03087，3正-2反 |
| 5    | 0.02048，2正-3反 | 0.01323，2正-3反 |

按照最大似然法则： 第1轮中最有可能的是硬币B 第2轮中最有可能的是硬币A 第3轮中最有可能的是硬币A 第4轮中最有可能的是硬币B 第5轮中最有可能的是硬币A。

我们就把概率更大，即更可能是A的，即第2轮、第3轮、第5轮出现正的次数2、1、2相加，除以A被抛的总次数15（A抛了三轮，每轮5次），**作为$z$的估计值**，B的计算方法类似。然后我们便可以按照最大似然概率法则来估计新的PA和PB。
$$
PA = \frac{2+1+2}{15} = 0.33 \\
PB =\frac{3+3}{10} = 0.6
$$
就这样，不断迭代,不断接近真实值，这就是**EM算法**的神奇之处。

继续按照上面的思路，用估计出的$PA$和$PB$再来估计$z$，再用$z$来估计新的$PA$和$PB$，反复迭代下去，就可以最终得到$PA = 0.4$，$PB=0.5$，此时无论怎样迭代，$PA$和$PB$的值都会保持0.4和0.5不变，于是乎，我们就找到了$PA$和$PB$的最大似然估计。

**计算步骤总结**

1. 随机初始化分布参数$\theta$

2. E步，求$Q$函数，对于每一个$i$，计算根据上一次迭代的模型参数来计算出隐性变量的**后验概率**（**隐性变量的期望**），来作为隐藏变量的现估计值：
   $$
   Q_{i}\left(z^{(i)}\right)=p\left(z^{(i)} \mid x^{(i)} ; \theta\right)
   $$

3. M步，求使$Q$函数获得极大时的**参数取值**,将**似然函数最大化**以**获得新的参数值**。
   $$
   \theta=\operatorname{argmax} \sum_{i} \sum_{z^{(i)}} Q_{i}\left(z^{(i)}\right) \log \frac{p\left(x^{(i)}, z^{(i)} ; \theta\right)}{Q_{i}\left(z^{(i)}\right)}
   $$

4. 然后**循环重复**2、3步直到**收敛**。

用EM算法求解的模型一般有GMM或者协同过滤，k-means其实也属于EM。EM算法一定会收敛，但是**可能收敛到局部最优**。由于求和的项数将随着隐变量的数目**指数上升**，会给**梯度计算**带来麻烦。





## 应用实践

> 介绍当下工业界下的机器学习应用
>
> * 中途会插入一部分Kaggle上的相关比赛

### 1 数据

> 数据是前提和基础，用于模型训练和检测

#### 1.1 数据获取

> example：

* MNIST：手写数字。

* ImageNet：Google引擎上获取下来的。

* AudioSet：YouTube上声音的数据集。

* SquAD: 从维基百科上获取的问题答案对应对。

  **主要获取数据方法：**

  * 手动制作
  * 爬取数据集

  **哪些网站可以获取数据集：**

* PaperWithCodes
* Kaggle
* Open Data on AWS
* Google Dataset Search

#### 1.2 网页数据爬取

> 对网页某个特定数据感兴趣

#### 1.3 代码实现

##### Numpy实现

